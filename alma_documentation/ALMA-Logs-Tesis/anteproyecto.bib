@article{Fayyad1996,
abstract = {Data mining and knowledge discovery in databases have been attracting a significant amount of research, industry, and media attention of late. What is all the excitement about? This article provides an overview of this emerging field, clarifying how data mining and knowledge discovery in databases are related both to each other and to related fields, such as machine learning, statistics, and databases. The article mentions particular real-world applications, specific data-mining techniques, challenges involved in real-world applications of knowledge discovery, and current and future research directions in the field. Copyright Â© 1996, American Association for Artificial Intelligence. All rights reserved.},
author = {Fayyad, Usama and Piatetsky-Shapiro, G and Smyth, Padhraic},
doi = {10.1145/240455.240463},
isbn = {0-262-56097-6},
issn = {0738-4602},
journal = {AI magazine},
pages = {37--54},
pmid = {12948721},
title = {{From data mining to knowledge discovery in databases}},
url = {http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/1230},
year = {1996}
}

@article{Russo2015,
author = {Russo, Barbara and Succi, Giancarlo and Pedrycz, Witold},
doi = {10.1007/s10664-014-9303-2},
file = {:Users/javier/Library/Application Support/Mendeley Desktop/Downloaded/Russo, Succi, Pedrycz - 2015 - Mining system logs to learn error predictors a case study of a telemetry system.pdf:pdf},
issn = {1382-3256},
journal = {Empirical Software Engineering},
number = {4},
pages = {879--927},
title = {{Mining system logs to learn error predictors: a case study of a telemetry system}},
url = {http://link.springer.com/10.1007/s10664-014-9303-2},
volume = {20},
year = {2015}
}
@article{Salfner2010,
abstract = {With the ever-growing complexity and dynamicity of computer systems, proactive fault management is an effective approach to enhancing availability. Online failure prediction is the key to such techniques. In contrast to classical reliability methods, online failure prediction is based on runtime monitoring and a variety of models and methods that use the current state of a system and, frequently, the past experience as well. This survey describes these methods. To capture the wide spectrum of approaches concerning this area, a taxonomy has been developed, whose different approaches are explained and major concepts are described in detail.},
author = {Salfner, Felix and Lenk, Maren and Malek, Miroslaw},
doi = {10.1145/1670679.1670680},
file = {:Users/javier/Library/Application Support/Mendeley Desktop/Downloaded/Salfner, Lenk, Malek - 2010 - A survey of online failure prediction methods.pdf:pdf},
isbn = {0360-0300},
issn = {03600300},
journal = {ACM Computing Surveys},
number = {3},
pages = {1--42},
title = {{A survey of online failure prediction methods}},
volume = {42},
year = {2010}
}
@article{Fronza2013,
author = {Fronza, Ilenia and Sillitti, Alberto and Succi, Giancarlo and Terho, Mikko and Vlasenko, Jelena},
doi = {10.1016/j.jss.2012.06.025},
file = {:Users/javier/Library/Application Support/Mendeley Desktop/Downloaded/Fronza et al. - 2013 - Failure prediction based on log files using Random Indexing and Support Vector Machines.pdf:pdf},
issn = {01641212},
journal = {Journal of Systems and Software},
number = {1},
pages = {2--11},
publisher = {Elsevier Inc.},
title = {{Failure prediction based on log files using Random Indexing and Support Vector Machines}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121212001732},
volume = {86},
year = {2013}
}
@article{Fulp2008,
abstract = {Mitigating the impact of computer failure is possible if accurate failure predictions are provided. Resources, applications, and services can be scheduled around predicted failure and limit the impact. Such strategies are especially important for multi-computer systems, such as compute clusters, that experience a higher rate failure due to the large number of components. However providing accurate predictions with sufficient lead time remains a challenging problem. This paper describes a new spectrum-kernel Support Vector Machine (SVM) approach to predict failure events based on system log files. These files containmessages that represent a change of system state. While a single message in the file may not be sufficient for predicting failure, a sequence or pattern of messages may be. The approach described in this paper will use a sliding window (sub-sequence) of messages to predict the likelihood of failure. The a frequency representation of the message sub-sequences observed are then used as input to the SVM. The SVM then associates the messages to a class of failed or non-failed system. Experimental results using actual system log files from a Linux-based compute cluster indicate the proposed spectrum-kernel SVM approach has promise and can predict hard disk failure with an accuracy of 73{\%} two days in advance.},
author = {Fulp, Ew and Fink, Ga and Haack, Jn},
file = {:Users/javier/Library/Application Support/Mendeley Desktop/Downloaded/Fulp, Fink, Haack - 2008 - Predicting Computer System Failures Using Support Vector Machines.pdf:pdf},
journal = {Proceedings of the First USENIX conference on Analysis of system logs},
pages = {5--5},
title = {{Predicting Computer System Failures Using Support Vector Machines.}},
year = {2008}
}
@article{Salfner2008,
author = {Salfner, Felix},
file = {:Users/javier/Library/Application Support/Mendeley Desktop/Downloaded/Salfner - 2008 - Event-based Failure Prediction An Extended Hidden Markov Model Approach.pdf:pdf},
isbn = {978-3-88579-413-4},
journal = {Ausgezeichnete Informatikdissertationen 2008},
pages = {231--240},
title = {{Event-based Failure Prediction: An Extended Hidden Markov Model Approach}},
volume = {D-9},
year = {2008}
}
@article{Salfner2008a,
author = {Salfner, Felix and Tschirpke, Steffen},
file = {:Users/javier/Library/Application Support/Mendeley Desktop/Downloaded/Salfner, Tschirpke - 2008 - Error Log Processing for Accurate Failure Prediction.pdf:pdf},
isbn = {0000000000000},
journal = {Wasl},
pages = {1--8},
title = {{Error Log Processing for Accurate Failure Prediction.}},
year = {2008}
}
@article{Salfner2004,
abstract = { Summary form only given. A proposal for a new generation of logfiles with regard to new challenges posed by autonomic computing is presented. While a variety of techniques are being developed on the way to autonomic computing, the problem of a system's logfiles remains to be critical. Several recommendations for logfile design are introduced: (a) Event type and source of events have to be distinguishably incorporated into the design, (b) Logfiles should incorporate hierarchical numbering schemes, (c) Information contained in logfiles should be categorized into classes, (d) Logfiles have to easily lend themselves to automatic analysis, (e) Information density of logfiles should be considered in the design of logging functionality. A metric to measure information entropy of logfiles is proposed. The type of information to be included in logfiles in order to support various aspects of autonomic computing as originally defined by IBM's eight elements is specified.},
author = {Salfner, F. and Tschirpke, S. and Malek, M.},
doi = {10.1109/IPDPS.2004.1303243},
file = {:Users/javier/Library/Application Support/Mendeley Desktop/Downloaded/Salfner, Tschirpke, Malek - 2004 - Comprehensive logfiles for autonomic systems.pdf:pdf},
isbn = {0-7695-2132-0},
journal = {18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.},
number = {C},
title = {{Comprehensive logfiles for autonomic systems}},
volume = {00},
year = {2004}
}

@inproceedings{Chiozzi2002,
abstract = {The Atacama Large Millimeter Array (ALMA) is a joint project between astronomical organizations in Europe and North America. ALMA will consist of at least 64 12-meter antennas operating in the millimeter and sub-millimeter range, with baselines up to 14 km. It will be located at an altitude above 5000m in the Chilean Atacama desert. The ALMA Common Software (ACS) provides a software infrastructure common to all partners and consists of a documented collection of common patterns and of components that implement those patterns. The heart of ACS is an object model based on Distributed Objects (DOs), implemented as CORBA objects. The teams responsible for the control system development use DOs as the basis for components and devices such as an antenna mount control. ACS provides common CORBA-based services such as logging, error and alarm management, configuration database and lifecycle management. A code generator creates a Java Bean for each DO. Programmers can write Java client applications by connecting those Beans with data-manipulation and visualization Beans. ACS is based on the experience gained in the astronomical and particle accelerator domains, and reuses and extends proven concepts and components. Although designed for ALMA, ACS can be used in other new control systems, since it implements proven design patterns using state of the art, stable and reliable technology. This paper presents the architecture of ACS and its status, detailing the object model and major services.},
author = {Chiozzi, Gianluca and Gustafsson, Birger and Jeram, Bogdan and Plesko, Mark and Sekoranja, Matej and Tkacik, Gasper and Zagar, K.},
booktitle = {Astronomical Telescopes and Instrumentation},
doi = {10.1117/12.461036},
pages = {43--54},
title = {{CORBA-based Common Software for the ALMA project}},
year = {2002}
}

@article{Cortes1995,
abstract = {The support-vector network is a new leaming machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high- dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demon- strated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Cortes, Corinna and Vapnik, Vladimir},
doi = {10.1007/BF00994018},
eprint = {arXiv:1011.1669v3},
isbn = {0885-6125},
issn = {08856125},
journal = {Machine Learning},
keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
number = {3},
pages = {273--297},
pmid = {9052598814225336358},
title = {{Support-vector networks}},
volume = {20},
year = {1995}
}

@article{Scholkopf2001,
abstract = {Suppose you are given some data set drawn from an underlying probability distribution P and you want to estimate a "simple" subset S of input space such that the probability that a test point drawn from P lies outside of S equals some a priori specified value between 0 and 1. We propose a method to approach this problem by trying to estimate a function f that is positive on S and negative on the complement. The functional form of f is given by a kernel expansion in terms of a potentially small subset of the training data; it is regularized by controlling the length of the weight vector in an associated feature space. The expansion coefficients are found by solving a quadratic programming problem, which we do by carrying out sequential optimization over pairs of input patterns. We also provide a theoretical analysis of the statistical performance of our algorithm. The algorithm is a natural extension of the support vector algorithm to the case of unlabeled data.},
author = {Sch{\"{o}}lkopf, B and Platt, J C and Shawe-Taylor, J and Smola, a J and Williamson, R C},
doi = {10.1162/089976601750264965},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural computation},
number = {7},
pages = {1443--1471},
pmid = {11440593},
title = {{Estimating the support of a high-dimensional distribution.}},
volume = {13},
year = {2001}
}


@online{ESO,
  author = {{European Southern Observatory}},
  title = {About ALMA},
  year = 2015,
  url = {https://web.archive.org/web/20151202195912/https://www.eso.org/sci/facilities/alma/about-alma.html},
  urldate = {2015-10-30}
}

@online{ESOLOG,
  author = {{European Southern Observatory}},
  title = {Logging and Archiving},
  year = 2007,
  url = {http://www.eso.org/~almamgr/AlmaAcs/OnlineDocs/Logging_and_Archiving.pdf},
  urldate = {2015-10-25}
}